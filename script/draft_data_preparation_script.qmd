---
title: "EDLD 651 Draft Data Preparation Script"
author: "Febe Lin, Ramtin Ranjpour, & James Phillips"
format:
  html:
    theme: cosmo         
    toc: true 
    toc-depth: 4           
    code-fold: false
    code-tools: true
    highlight-style: github
    embed-resources: true
execute:                
  warning: false
  message: false
  echo: true
editor: visual
---

```{r}
#| include: false
library(rio)
library(here)
library(tidyverse)
library(tidylog)
library(janitor)
library(skimr)
library(knitr)
```

# Load the data set

```{r}
student_social <- import(here("data", "final_students_social_media.csv"))

head(student_social)
```

The data is not tidy because the column names (Instagram, TikTok, etc.) are actually values of a variable, not the names of variables themselves.

# Clean the data

```{r}
tidy_data <- student_social |> 
  pivot_longer(cols = Instagram : last_col(),
               names_to ="Most_Used_Platform",
               values_to = "Avg_Daily_Usage_Hours",
               values_drop_na = TRUE)

head(tidy_data)

export(tidy_data, here("data", "tidy_data.csv"))
```

# Explore our questions

## RQ1-RQ2, H1-H3

*RQ*~1~: Does sleep deprivation mediate the negative relationship between daily screen time and mental health scores?

*H*~1~: Screen time negatively predicts sleep time, which in turn negatively impacts mental health.

```{r}
# test mental ~ screen time
model_test <-lm(Mental_Health_Score~Avg_Daily_Usage_Hours,data = tidy_data)
summary(model_test)

# test sleep hours ~ screen time
model_path_a <- lm(Sleep_Hours_Per_Night ~ Avg_Daily_Usage_Hours, data = tidy_data)
summary(model_path_a)

# test mental ~ screen time + sleep hours
model_full <- lm(Mental_Health_Score ~ Avg_Daily_Usage_Hours + Sleep_Hours_Per_Night, data = tidy_data)
summary(model_full)


#plot
ggplot(tidy_data,
       aes(x= Avg_Daily_Usage_Hours, y= Mental_Health_Score))+
  geom_smooth(model= "lm", se= TRUE)+
  labs(x = "Average Screen Time on the Most Used Social Media Platform (hrs)",
       y = "Mental Health Score (Range 4-9)",
       title = "Relationship between Screen Time and Mental Health")+
  theme_minimal()+
  theme(plot.title = element_text(size =10))


ggplot(tidy_data,
       aes(x= Avg_Daily_Usage_Hours, y= Sleep_Hours_Per_Night))+
  geom_smooth(model= "lm", se= TRUE, color = "red")+
  labs(x = "Average Screen Time on the Most Used Social Media Platform (hrs)",
       y = "Sleep per Night (hrs)",
         title = "Relationship between Screen Time and Sleep hours")+
  theme_minimal()+
  theme(plot.title = element_text(size =10))



```

![](images/mediation_analysis_diagram-01.png)

Based on the result, H1 was supported. For better understand the relationship, we draw a path analysis figure. From this figure we can see that overall, longer screen-time usage significantly harms mental health (coeff = −0.70). This also supports our hypothesis that sleep duration partially mediates this relationship: excessive screen time reduces sleep, which in turn contributes to poorer mental health. However, this is not the whole story. Even after accounting for sleep and ensuring adequate sleep duration, screen overuse still shows a significant direct negative effect on mental health (direct coeff= −0.57), suggesting that excessive screen use may harm mental health through additional mechanisms beyond sleep.

*RQ*~2~:Is there a critical 'tipping point' in screen usage where sleep duration and mental health exhibit a sharp decline?

-   *H*~2~: Students exceeding a threshold of 5 hours per day will report significantly worse outcomes compared to low-usage groups, whereas the difference between low (0\~3) and moderate usage (3\~5)may be minimal. (In my own experience, I use screens for 3--5 hours per day and do not perceive any notable mental-health issues)
-   *H*~3~: However, this pattern may vary by gender, and the differences in outcomes may not be the same across male and female students.

```{r}
group_data <- tidy_data |> 
  mutate(Usage_Group = cut(
      Avg_Daily_Usage_Hours,
      breaks = c(0, 3, 5, Inf),
      labels = c("Low (0–3h)", "Moderate (3–5h)", "High (>5h)"))
      ) 

male_data <- group_data |> 
  filter(Gender == "Male") |> 
  select(Gender, Avg_Daily_Usage_Hours, Sleep_Hours_Per_Night,Mental_Health_Score,Usage_Group) 


female_data <- group_data |> 
  filter(Gender == "Female") |> 
  select(Gender, Avg_Daily_Usage_Hours, Sleep_Hours_Per_Night,Mental_Health_Score,Usage_Group)
```

```{r}

summary_data <- group_data |>
  group_by(Gender, Usage_Group) |>
  summarise(
    mean_MH = mean(Mental_Health_Score),
    sd_MH   = sd(Mental_Health_Score),
    n       = n(),
    se_MH   = sd_MH / sqrt(n) 
  ) |>
  ungroup()

ggplot(summary_data,
       aes(x = Usage_Group,
           y = mean_MH,
           group = Gender,
           color = Gender)) +
  geom_point(position = position_dodge(width = 0.2), size = 3) +
  geom_line(position = position_dodge(width = 0.2)) +
  geom_errorbar(
    aes(ymin = mean_MH - se_MH,
        ymax = mean_MH + se_MH),
    width = 0.1,
    position = position_dodge(width = 0.2)
  ) +
  labs(
    x = "Daily Screen Time Group",
    y = "Mean Mental Health Score",
    color = "Gender",
    title = "Mental Health by Screen Time Group and Gender"
  ) +
  theme_minimal()

```

It does show a negative effect of daily screen time on mental health, but there is no clear "tipping point." Instead, the decline appears more stepwise, with mental health decreasing gradually across each usage group.

The most interesting finding is that the downward trend is evident for both genders, but the decline is notably steeper among female students, especially in the high-usage category, suggesting that excessive screen exposure may have a stronger negative impact on females' psychological well-being.

To statistically verify the patterns observed in the plot, we conducted separate one-way ANOVAs for male and female students

```{r}
#one-way ANOVAs
anova_male <- aov(Mental_Health_Score ~ Usage_Group, data = male_data)
TukeyHSD(anova_male)

anova_female <- aov(Mental_Health_Score ~ Usage_Group, data = female_data)
TukeyHSD(anova_female)
```

The post hoc Tukey tests confirmed significant differences across all usage groups in both genders, with female students showing larger mean declines, particularly between the moderate and high usage levels.

## RQ3-RQ5, H4

*RQ*~3~: How does primary usage of a specific social media platform impact mental health?

*H*~4~: Meta-affiliated platforms, such as Facebook and Instagram, will result in a greater impact to mental health compared to other platforms.

```{r}
#| include: false
platform_use <- tidy_data |> 
  mutate(
    Most_Used_Platform = factor(Most_Used_Platform),
    Gender = factor(Gender),
    Academic_Level = factor(Academic_Level),
    Country = factor(Country)
  )

str(platform_use)
summary(platform_use$Most_Used_Platform)
```

```{r}
platform_mental_health <- platform_use |> 
  group_by(Most_Used_Platform) |> 
  summarize(
    n = n(),
    mean_pmh = mean(Mental_Health_Score, na.rm = TRUE),
    sd_pmh = sd(Mental_Health_Score, na.rm = TRUE)
  ) |> 
  arrange(mean_pmh) |> 
  rename(
    `Most Used Platform` = Most_Used_Platform,
    Mean = mean_pmh,
    `Standard Deviation` = sd_pmh
  )

platform_mental_health |> 
  kable(
    caption = "Mean Mental Health Scores by Platform",
    digits = 2
  )
```

Based on the results in this table, we cannot definitively correlate the use of Meta-owned platforms to lower self-reported mental health scores. *H*~4~ is not supported. <!--# It seems like you didn't include any t-test to compare the means for meta-owned platform vs others. The first step would be group the most-used platform based on this criteria. Would it also make sense to group some of the other ones based on ownership? Alternatively, it could be easier if it's just meta-owned vs all others, then you can simply conduct a t-test to compare the group mean of meta-owned platform vs others. -->

*RQ*~4~: Do any specific social media platforms significantly correlate to lower self-reported mental health statuses?

```{r}
pu_mean_mh <- mean(platform_use$Mental_Health_Score, na.rm = TRUE)

platform_use <- platform_use |> 
  mutate(
    low_mh = if_else(Mental_Health_Score < pu_mean_mh, "Low", "Not Low"),
    low_mh = factor(low_mh, levels = c("Low", "Not Low"))
  )

mh_count <- platform_use |> 
  group_by(Most_Used_Platform, low_mh) |> 
  summarize(
    n = n(),
    .groups = "drop"
  )

mh_wide <- mh_count |> 
  pivot_wider(
    names_from = low_mh,
    values_from = n,
    values_fill = 0
  )

mh_wide <- mh_wide |> 
  mutate(
    total = Low + `Not Low`,
    pct_low = Low / total * 100,
    pct_not_low = `Not Low` / total * 100
  ) |> 
  mutate(
    pct_low = round(pct_low, 1),
    pct_not_low = round(pct_not_low, 1)
  ) |> 
  rename(
    `Most Used Platform` = Most_Used_Platform,
    Total = total,
    `Low (%)` = pct_low,
    `Not Low (%)` = pct_not_low
  )

mh_wide |>
  select(-Low, -`Not Low`, -Total) |> 
  kable(
    caption = "Percentages of Lower Than Average Mental Health Reports by Platform",
    digits = 3
  )
# It took me a while to figure out what was the goal for this section of code, for reproducibility purpose, it will be great to include a short description for the goal of each step and this code chunk.
```

An initial glance at this data suggested that the majority of those who primarily use Instagram, KakaoTalk, Snapchat, TikTok, WeChat, and WhatsApp have lower-than-average reported mental health. Using a chi-square test of independence, we sought to measure if these differences reflect a statistically significant relationship instead of chance.

```{r}
mh_chi <- mh_wide |> 
  select(Low, `Not Low`) |> 
  as.matrix()

rownames(mh_chi) <- mh_wide$Most_Used_Platform

mh_chi <- chisq.test(mh_chi)

mh_chi
```

These results indicated a significant association between primary platform use and reported mental health status (χ² = 226.05, *df* = 11, *p* \< .001), suggesting that low versus not-low mental health frequencies vary across platforms to a noteworthy degree.

*RQ*~5~: Do any specific platforms correlate to higher levels of social media addiction?

```{r}
platform_addiction <- platform_use |> 
  group_by(Most_Used_Platform) |> 
  summarize(
    n = n(),
    mean_addiction = mean(Addicted_Score, na.rm = TRUE),
    sd_addiction = sd(Addicted_Score, na.rm = TRUE)
  ) |> 
  rename(
    `Most Used Platform` = Most_Used_Platform,
    `Mean` = mean_addiction,
    `Standard Deviation` = sd_addiction
  ) |> 
  arrange(desc(`Mean`))

platform_addiction |> 
  kable(
    caption = "Social Media Addiction by Platform",
    digits = 2
  )
```

The resulting data indicated that those who reported using WhatsApp or Snapchat the most also reported the highest level of addiction to social media (*M~WA~* = 7.46, *SD* = 0.50; *M~S~* = 7.46, *SD* = 0.78), closely followed by those who reported TikTok as their most used platform (*M* = 7.43, *SD* = 1.04). Those who reported using LINE as their most used platform reported the lowest level of addiction to social media (*M* = 3.00, *SD* = 0.00).

## RQ6

*RQ*~6~: Among college students, comparing students from the US to those from the Middle East and the Far East, how does mental health affect conflicts over social media?

For this question, we are filtering the responses into three groups by country: the USA, the Middle Easterns, and the Far Easterns. We are also exclusively looking at college students, both undergrad and grad, thereby removing high schoolers.

```{r}
sm <- import(here("data", "tidy_data.csv")) |>
  clean_names()
  
middle_east <- c("Bahrain", "Iraq", "Israel", "Jordan", "Kuwait",
                 "Lebanon", "Oman", "Qatar", "Syria", "Turkey",
                 "UAE", "Yemen")

far_east <- c("China", "Japan", "South Korea", "Taiwan", "Singapore",
              "Malaysia", "Indonesia", "Vietnam", "Philippines",
              "Thailand", "Hong Kong")

# Use the right column and classifications to filter for college students.
# Create a new column for our three regions.
students <- sm |>
  filter(academic_level %in% c("Undergraduate", "Graduate")) |>
  mutate(
    region = case_when(
      country == "USA" ~ "USA",
      country %in% middle_east ~ "Middle East",
      country %in% far_east ~ "Far East",
      TRUE ~ NA_character_
    )
  ) |>
  filter(!is.na(region)) |> # Select the columns to use.
  select(student_id,
         region,
         academic_level,
         age,
         gender,
         mental_health_score,
         conflicts_over_social_media)

skim(students) # For a quick check.
```

Now we can run inferential tests with mental health as the IV, region as the grouping, and conflicts over social media as the DV.

```{r}
# Center mental health.
students <- students |>
  mutate(mh_c = scale(mental_health_score, center = TRUE, scale = FALSE))

# Interaction model for differences by region.
model_int <- lm(conflicts_over_social_media ~ mh_c * region, data = students)
summary(model_int)

anova(model_int)

# Correlation by region.
cor_by_region <- students |>
  group_by(region) |>
  summarise(
    n = n(),
    r_mh_conflict = cor(mental_health_score,
                        conflicts_over_social_media,
                        use = "pairwise.complete.obs")
  )

kable(cor_by_region, digits = 3,
      caption = "Correlation Between Mental Health and Social Media Conflicts by Region")

# Few basic descriptive statistics.
desc_table <- students |>
  group_by(region) |>
  summarise(
    n = n(),
    mean_mh = mean(mental_health_score, na.rm = TRUE),
    sd_mh   = sd(mental_health_score, na.rm = TRUE),
    mean_conflict = mean(conflicts_over_social_media, na.rm = TRUE),
    sd_conflict   = sd(conflicts_over_social_media, na.rm = TRUE)
  )
```

With a multiple regression model that included centered mental health scores, three regions, and their interaction, the descriptive statistics show that students from the Far East reported the highest mental health scores (M = 6.77, SD = 0.91) and the lowest social media conflict levels (M = 2.30, SD = 0.86), followed by students from the Middle East next (M = 5.71, SD = 0.75; M = 3.27, SD = 0.81, respectively) and the United States last (M = 4.90, SD = 0.71; M = 3.80, SD = 0.41). Mental health was strongly and negatively associated with social media conflict across the board, and the relationship varied by the region, with the strongest correlations observed in the Middle East (r = −.98), followed by the Far East (r = −.90) and the United States (r = −.79). It was also revealed that the strength of this association was significantly different across regions, which suggest that poorer mental health predicts higher levels of confict over social media more strongly in the Middle East and the Far East in comparison to students in the US.

```{r}
ggplot(students,
       aes(x = mental_health_score,
           y = conflicts_over_social_media,
           color = region)) +
  geom_jitter(width = 0.1, height = 0.1, alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, size = 1.1) +
  labs(
    title = "Mental Health and Conflicts Over Social Media by Region",
    x = "Mental Health Score",
    y = "Conflicts Over Social Media",
    color = "Region"
  ) +
  theme_minimal()

students |>
  group_by(region) |>
  summarise(mean_conflict = mean(conflicts_over_social_media, na.rm = TRUE)) %>%
  ggplot(aes(x = region, y = mean_conflict, fill = region)) +
  geom_col() +
  labs(
    title = "Average Social Media Conflicts by Region for College Students",
    x = "Region",
    y = "Mean Conflict Score"
  ) +
  theme_minimal() +
  theme(legend.position = "none")
```
